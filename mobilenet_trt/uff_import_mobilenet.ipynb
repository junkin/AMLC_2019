{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook looks at taking a frozen tensorflow model (of mobilenet) which has been converted to UFF with the uff_convert tool and building a tensorRT optimized plan.  Then using this plan with the tensorRT runtime to execute inference in native TRT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the imports needed to build a trt python api based network, cuda interface, and image manipulation for preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We will pull a pre converted model file from S3 for this inference engine and also a set of images to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash ./setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_BATCH_SIZE = 1\n",
    "#workspace size matters!  try with 20 and look at the output - not all tactics will be able to run as some need scracth space beyond that size.\n",
    "\n",
    "MAX_WORKSPACE_SIZE = 1 << 30\n",
    "\n",
    "#with loglevel set to INFO the trt library will use STDERR to outline the details of the optimization path.\n",
    "#switch to the console to look at the optimizations, fusions, tactic timings done on the model.\n",
    "LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "DTYPE = trt.float32\n",
    "\n",
    "# Model\n",
    "MODEL_FILE = 'mobilenet_v1_1.0_224.uff'\n",
    "INPUT_NAME = 'input'\n",
    "INPUT_SHAPE = (3, 224, 224)\n",
    "OUTPUT_NAME = 'MobilenetV1/Predictions/Reshape_1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_buffers(engine):\n",
    "    h_input = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(0)), dtype=trt.nptype(DTYPE))\n",
    "    h_output = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(1)), dtype=trt.nptype(DTYPE))\n",
    "    d_input = cuda.mem_alloc(h_input.nbytes)\n",
    "    d_output = cuda.mem_alloc(h_output.nbytes)\n",
    "\n",
    "    return h_input, d_input, h_output, d_output\n",
    "\n",
    "\n",
    "def build_engine(model_file, fp16=False):\n",
    "    with trt.Builder(LOGGER) as builder, builder.create_network() as network, trt.UffParser() as parser:\n",
    "        builder.max_workspace_size = MAX_WORKSPACE_SIZE\n",
    "        builder.max_batch_size = MAX_BATCH_SIZE\n",
    "        if fp16:\n",
    "            builder.fp16_mode = True\n",
    "        parser.register_input(INPUT_NAME, INPUT_SHAPE, trt.UffInputOrder.NCHW)\n",
    "        parser.register_output(OUTPUT_NAME)\n",
    "        parser.parse(model_file, network, DTYPE)\n",
    "\n",
    "        return builder.build_cuda_engine(network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input(img_path, host_buffer):\n",
    "    print('load input')\n",
    "\n",
    "    with Image.open(img_path) as img:\n",
    "        c, h, w = INPUT_SHAPE\n",
    "        dtype = trt.nptype(DTYPE)\n",
    "        img_array = np.asarray(img.resize((w, h), Image.BILINEAR)).transpose([2, 0, 1]).astype(dtype).ravel()\n",
    "        # preprocess for mobilenet\n",
    "        img_array = img_array / 127.5 - 1.0\n",
    "\n",
    "    np.copyto(host_buffer, img_array)\n",
    "\n",
    "\n",
    "def do_inference(n, context, h_input, d_input, h_output, d_output):\n",
    "    # Transfer input data to the GPU.\n",
    "    cuda.memcpy_htod(d_input, h_input)\n",
    "\n",
    "    # Run inference.\n",
    "    st = time.time()\n",
    "    context.execute(batch_size=1, bindings=[int(d_input), int(d_output)])\n",
    "    print('Inference time {}: {} [msec]'.format(n, (time.time() - st)*1000))\n",
    "\n",
    "    # Transfer predictions back from the GPU.\n",
    "    cuda.memcpy_dtoh(h_output, d_output)\n",
    "\n",
    "    return h_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls\n",
    "!ls ./calibration_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = \"mobilenet_labels.txt\"\n",
    "with open(LABELS) as f:\n",
    "     labels = f.read().split('\\n')\n",
    "\n",
    "    \n",
    "engine = build_engine(MODEL_FILE)\n",
    "h_input, d_input, h_output, d_output = allocate_buffers(engine)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = \"./calibration_images/dolphin-203875_960_720.jpg\"\n",
    "\n",
    "from IPython.display import Image as Img\n",
    "display(Img(img_file))\n",
    "\n",
    "load_input(img_file, h_input)\n",
    "with engine.create_execution_context() as context:\n",
    "    \n",
    "    output = do_inference(1, context, h_input, d_input, h_output, d_output)\n",
    "\n",
    "    pred_idx = np.argsort(output)[::-1]\n",
    "    pred_prob = np.sort(output)[::-1]\n",
    "\n",
    "    print('\\nClassification Result:')\n",
    "    for i in range(5):\n",
    "        print('{} {} {:.5f}'.format(i + 1, labels[pred_idx[i]], pred_prob[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets serialize this engine so we can use it later, and also create a fp16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mobilenet.engine32', 'wb') as f:\n",
    "   f.write(engine.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = build_engine(MODEL_FILE, True)\n",
    "with open('mobilenet.engine16', 'wb') as f:\n",
    "   f.write(engine.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a profile using Nsight systems command line to explore the system-gpu interaction.  we will need to download the output file mobilenet_fp16.qdrep (or 32.qdrep for the FP32 engine) locally to open in the visual explorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nsys profile --show-output true --output mobilenet_fp16 --trace osrt,cuda,cudnn,cublas,nvtx  python do_inference.py mobilenet.engine ./calibration_images/fish-3322230_960_720.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nsys profile --show-output true --output mobilenet_fp32 --trace osrt,cuda,cudnn,cublas,nvtx  python do_inference.py mobilenet.engine32 ./calibration_images/fish-3322230_960_720.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nsight compute command to look at tensor core Metrics:\n",
    "nv-nsight-cu-cli --metrics tensor_precision_fu_utilization python do_inference.py mobilenet.engine32 ./calibration_images/fish-3322230_960_720.jpg\n",
    "\n",
    "to run  profile tool over entire network:\n",
    "!nv-nsight-cu-cli python do_inference.py mobilenet.engine16 ./calibration_images/fish-3322230_960_720.jpg\n",
    "!nv-nsight-cu-cli -k fusedConvolutionReluKernel -s 11 -c 1 '/usr/bin/python' do_inference.py mobilenet.engine32 ./calibration_images/fish-3322230_960_720.jpg\n",
    "\n",
    "to generate an nsight compute profile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nv-nsight-cu-cli -o profile python do_inference.py mobilenet.engine16 ./calibration_images/fish-3322230_960_720.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
